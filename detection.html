<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Drowsiness Detection</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-image: url("{{ url_for('static', filename='driver.jpg') }}");
            margin: 0;
            padding: 0;
            text-align: center;
        }


        body {
    font-family: Arial, sans-serif;
    background-color: #f5f5f5;
    margin: 0;
    padding: 0;
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    height: 100vh; /* 100% de la hauteur de la vue */
}

h1 {
    color: #333;

}

#video-feed {
    margin: 20px auto;
    display: flex;
    flex-direction: column;
    align-items: center;
}

button {
    margin-top: 20px;
    padding: 10px 20px;
    font-size: 16px;
    background-color: #3498db;
    color: #fff;
    border: none;
    cursor: pointer;
    transition: background-color 0.3s ease;
}

button:hover {
    background-color: #2980b9;
}

video {
    margin-top: 10px;
    max-width: 30%;
}

canvas {
    display: none;
}

    </style>
</head>

<body>
    <h1> Driver Monitoring System </h1>

    </body>


    <div id="video-feed"></div>
    <button onclick="startDetection()">Start Detection</button>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.0.1/socket.io.js"></script>

<script>
    const socket = io.connect('http://' + document.domain + ':' + location.port);

    function startDetection() {
        socket.emit('detect_button');
        const videoFeed = document.getElementById('video-feed');
        const video = document.createElement('video');
        video.autoplay = true;
        videoFeed.appendChild(video);

        navigator.mediaDevices.getUserMedia({ video: true })
            .then(stream => {
                video.srcObject = stream;

                const canvas = document.createElement('canvas');
                const context = canvas.getContext('2d');
                videoFeed.appendChild(canvas);

                video.addEventListener('loadedmetadata', () => {
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;

                    const faceCascade = new cv.CascadeClassifier();
                    faceCascade.load('haarcascade_frontalface_alt.xml'); // Remplacez par le bon chemin
                    const gray = new cv.Mat();
                    const faces = new cv.RectVector();

                    const processVideo = () => {
                        context.drawImage(video, 0, 0, canvas.width, canvas.height);
                        cv.cvtColor(cv.imread(canvas), gray, cv.ColorConversionCodes.COLOR_RGBA2GRAY);
                        const size = new cv.Size(0, 0);
                        faceCascade.detectMultiScale(gray, faces, 1.1, 3, 0, size, size);

                        for (let i = 0; i < faces.size(); ++i) {
                            const face = faces.get(i);
                            const point1 = new cv.Point(face.x, face.y);
                            const point2 = new cv.Point(face.x + face.width, face.y + face.height);
                            context.lineWidth = 2;
                            context.strokeStyle = 'red';
                            context.beginPath();
                            context.rect(point1.x, point1.y, face.width, face.height);
                            context.stroke();
                        }

                        requestAnimationFrame(processVideo);
                    };

                    processVideo();
                });
            })
            .catch(error => {
                console.error('Error accessing camera: ', error);
            });
    }

</script>

</html>
